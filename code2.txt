from picamera2 import Picamera2
import torch
import cv2
import numpy as np
from models.experimental import attempt_load
from utils.general import non_max_suppression, scale_coords
import pygame
import threading
import time

# Initialize picamera2
picam2 = Picamera2()
picam2.configure(picam2.create_still_configuration())
picam2.start()

# Load YOLOv7 model (update the path to your custom model weights)
model = attempt_load('/path/to/your/custom_model.pth', map_location=torch.device('cpu'))

# Set the model to evaluation mode
model.eval()

# Dynamically fetch class names if available
try:
    class_names = model.names  # Model should have a 'names' attribute with class labels
except AttributeError:
    # Fallback to manual class names (update this to match your dataset)
    class_names = ["class_0", "class_1", "monkey"]  # Replace with your actual class labels

# Define image size expected by YOLOv7 (e.g., 416x416 for your training configuration)
img_size = 416

# Set the desired resolution for the display
screen_width = 800  # Resolution width for the 5-inch HDMI display
screen_height = 480  # Resolution height for the 5-inch HDMI display

# Path to the audio file (update this to your desired sound file path)
audio_file = "/path/to/monkey_detected.wav"  # Ensure this is a .wav file

# Initialize Pygame mixer
pygame.mixer.init()

# Flag to manage sound playback cooldown
last_play_time = 0
cooldown = 10  # Cooldown in seconds

# Function to play audio using pygame
def play_sound(audio_file):
    pygame.mixer.music.load(audio_file)
    pygame.mixer.music.play()

while True:
    # Capture an image from the camera
    image = picam2.capture_array()

    # Convert the image from RGB to BGR (OpenCV uses BGR format)
    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

    # Resize image to the required input size for YOLOv7 (416x416)
    img_resized = cv2.resize(image_bgr, (img_size, img_size))

    # Normalize the image and convert to tensor
    img_normalized = img_resized / 255.0  # Normalize to [0, 1]
    img_tensor = torch.from_numpy(img_normalized).float().permute(2, 0, 1).unsqueeze(0)  # CxHxW format
    img_tensor = img_tensor.to(torch.device('cpu'))  # Move the tensor to CPU

    # Perform YOLOv7 inference
    with torch.no_grad():
        results = model(img_tensor)[0]  # Get raw detections

        # Apply Non-Max Suppression (NMS) to filter results
        results = non_max_suppression(results, conf_thres=0.25, iou_thres=0.45)[0]

    # Scale the bounding boxes back to the original image size
    if results is not None and len(results):
        results[:, :4] = scale_coords(img_tensor.shape[2:], results[:, :4], image_bgr.shape).round()

        # Loop through detections and draw bounding boxes
        for *xyxy, conf, cls in results:
            cls_idx = int(cls)  # Convert class tensor to integer
            if cls_idx < len(class_names):  # Check if class index is valid
                label = f"{class_names[cls_idx]} {conf:.2f}"
            else:
                label = f"Unknown {conf:.2f}"
            
            # Print the detected class and confidence
            print(f"Detected: {label}")

            # Play audio if a monkey is detected and cooldown period has passed
            current_time = time.time()
            if class_names[cls_idx].lower() == "monkey" and (current_time - last_play_time > cooldown):
                last_play_time = current_time
                threading.Thread(target=play_sound, args=(audio_file,)).start()

            # Draw bounding box and label
            x1, y1, x2, y2 = map(int, xyxy)  # Convert to int for OpenCV
            cv2.rectangle(image_bgr, (x1, y1), (x2, y2), (255, 0, 0), 2)
            cv2.putText(image_bgr, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

    # Resize image to match the 5-inch HDMI display resolution (800x480)
    image_resized = cv2.resize(image_bgr, (screen_width, screen_height))

    # Display the frame with bounding boxes
    cv2.imshow("YOLOv7 Detection", image_resized)

    # Exit on 'q' key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Stop the camera and close OpenCV window
picam2.stop()
cv2.destroyAllWindows()
