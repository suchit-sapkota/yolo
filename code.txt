from picamera2 import Picamera2
import time
import torch
import cv2
import numpy as np

# Initialize picamera2
picam2 = Picamera2()
picam2.configure(picam2.create_still_configuration())
picam2.start()

# Import YOLOv7 model from the local clone
from models.experimental import attempt_load
from utils.general import non_max_suppression, scale_coords, xyxy2xywh

# Load the YOLOv7 model (make sure to adjust the path to your weights)
model = attempt_load('/path/to/your/custom_model.pth', map_location=torch.device('cpu'))

# Set the model to evaluation mode
model.eval()

# Define the image size expected by YOLOv7 (640x640 for default)
img_size = 640

# Define class names (replace with your custom classes if applicable)
class_names = ["class_0", "class_1", "class_2"]  # Replace with your actual class names

while True:
    # Capture an image from the camera
    image = picam2.capture_array()

    # Convert the image from RGB to BGR (OpenCV uses BGR format)
    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

    # Resize image to the required input size for YOLOv7 (640x640)
    img_resized = cv2.resize(image_bgr, (img_size, img_size))

    # Normalize the image and convert to tensor
    img_normalized = img_resized / 255.0  # Normalize to [0, 1]
    img_tensor = torch.from_numpy(img_normalized).float().permute(2, 0, 1).unsqueeze(0)  # CxHxW format
    img_tensor = img_tensor.to(torch.device('cpu'))  # Move the tensor to CPU

    # Perform YOLOv7 inference
    with torch.no_grad():
        # Get the raw inference result
        results = model(img_tensor)[0]

        # Apply Non-Max Suppression (NMS) to filter results
        results = non_max_suppression(results, conf_thres=0.25, iou_thres=0.45)[0]

    # Scale the bounding boxes back to the original image size
    if results is not None and len(results):
        results[:, :4] = scale_coords(img_tensor.shape[2:], results[:, :4], image_bgr.shape).round()

        # Loop through detections and draw bounding boxes
        for *xyxy, conf, cls in results:
            label = f"{class_names[int(cls)]} {conf:.2f}"
            x1, y1, x2, y2 = map(int, xyxy)  # Convert to int for OpenCV
            cv2.rectangle(image_bgr, (x1, y1), (x2, y2), (255, 0, 0), 2)
            cv2.putText(image_bgr, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

    # Display the frame with bounding boxes
    cv2.imshow("YOLOv7 Detection", image_bgr)

    # Exit on 'q' key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Stop the camera and close OpenCV window
picam2.stop()
cv2.destroyAllWindows()
