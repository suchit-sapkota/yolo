import cv2
import numpy as np
import time
import tflite_runtime.interpreter as tflite
from picamera2 import Picamera2

# Load YOLOv7 TFLite model
model_path = "yolov7.tflite"
interpreter = tflite.Interpreter(model_path=model_path)
interpreter.allocate_tensors()

# Get input and output details
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Extract the expected input shape (batch, height, width, channels)
_, input_height, input_width, input_channels = input_details[0]['shape']

# Ensure the model expects 3 channels (RGB)
assert input_channels == 3, f"Model expects {input_channels} channels, but input has 3"

# Initialize Raspberry Pi Camera
picam2 = Picamera2()
picam2.preview_configuration.main.size = (640, 480)
picam2.preview_configuration.main.format = "RGB888"
picam2.configure("preview")
picam2.start()

# Function to preprocess the frame
def preprocess_frame(frame):
    image = cv2.resize(frame, (input_width, input_height))  # Resize to model's input size
    image = image.astype(np.float32) / 255.0  # Normalize pixel values
    image = np.expand_dims(image, axis=0)  # Add batch dimension
    return image

# Object detection loop
while True:
    start_time = time.time()

    # Capture frame from Pi Camera
    frame = picam2.capture_array()
    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  # Convert to OpenCV BGR format
    original_frame = frame.copy()
    
    # Preprocess the frame
    image = preprocess_frame(frame)

    # Ensure input tensor shape matches
    if image.shape != (1, input_height, input_width, input_channels):
        print(f"Error: Input shape mismatch. Expected {(1, input_height, input_width, input_channels)}, but got {image.shape}")
        continue

    # Set input tensor
    interpreter.set_tensor(input_details[0]['index'], image)

    # Run inference
    interpreter.invoke()

    # Get output tensors
    boxes = interpreter.get_tensor(output_details[0]['index'])  # Bounding boxes
    classes = interpreter.get_tensor(output_details[1]['index'])  # Class IDs
    scores = interpreter.get_tensor(output_details[2]['index'])  # Confidence scores

    # Draw results
    h, w, _ = original_frame.shape
    for i in range(len(scores[0])):
        if scores[0][i] > 0.5:  # Confidence threshold
            ymin, xmin, ymax, xmax = boxes[0][i]  # Bounding box
            class_id = int(classes[0][i])
            confidence = scores[0][i]

            # Scale bounding box to original frame size
            xmin, xmax = int(xmin * w), int(xmax * w)
            ymin, ymax = int(ymin * h), int(ymax * h)

            # Draw bounding box
            cv2.rectangle(original_frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)
            label = f"Class {class_id}: {confidence:.2f}"
            cv2.putText(original_frame, label, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Display frame
    cv2.imshow("YOLOv7 TFLite Live Detection", original_frame)

    # Exit on 'q' key press
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

    end_time = time.time()
    print(f"FPS: {1 / (end_time - start_time):.2f}")

# Cleanup
cv2.destroyAllWindows()
picam2.stop()
